```{r}
anes_2008tr <- read.csv("C:/Users/monabiyan/SkyDrive/Summer 2015/Statistics/HW8/anes_2008tr.csv",sep=",",header=TRUE,stringsAsFactors=FALSE)
age_mean=mean(anes_2008tr$age)
income_mean=mean(anes_2008tr$income)
ideology_mean=mean(anes_2008tr$ideology_con)
head(anes_2008tr$vote_rep)
anes_2008tr$vote_rep
anes_2008tr$voted
lr1 <- glm(vote_rep ~ age + race_white + gender_male + education +
income + ideology_con + I(ideology_con^2) + partyid_rep,
data=anes_2008tr,family="binomial")
summary(lr1)
lr1 <- glm(vote_rep ~ age + race_white + gender_male + education + income + ideology_con + I(ideology_con^2) + partyid_rep,data=anes_2008tr,family="binomial")
summary(lr1)
summary(lr1)
lr1 <- glm(vote_rep ~ age + race_white + gender_male + education + income + ideology_con + I(ideology_con^2) + partyid_rep,data=anes_2008tr,family="binomial")
summary(lr1)
lr1 <- glm(vote_rep ~ age + income + ideology_con,data=anes_2008tr,family="binomial")
summary(lr1)
exp(lr1$coef)
exp(lr1$coef)[1]
exp(lr1$coef)[1][1]
mode(exp(lr1$coef)[1])
class(exp(lr1$coef)[1])
exp_B0=as.numeric(exp(lr1$coef)[1])
exp_B0
probability_vote_rep<-(exp_B0*exp_B1*exp_B2*exp_B3)/(1+exp_B0*exp_B1*exp_B2*exp_B3)
exp_B0=as.numeric(exp(lr1$coef)[1])
exp_B1=as.numeric(exp(lr1$coef)[2])
exp_B2=as.numeric(exp(lr1$coef)[3])
exp_B3=as.numeric(exp(lr1$coef)[4])
probability_vote_rep<-(exp_B0*exp_B1*exp_B2*exp_B3)/(1+exp_B0*exp_B1*exp_B2*exp_B3)
probability_vote_rep
anes_2008tr$race_white
lr1 <- glm(vote_rep ~ age + income + ideology_con+race_white,data=anes_2008tr,family="binomial")
summary(lr1)
lr1 <- glm(vote_rep ~ age + income + ideology_con+race_white,data=anes_2008tr,family="binomial")
summary(lr1)
exp_B0=as.numeric((lr1$coef)[1])
exp_B1=as.numeric((lr1$coef)[2])
exp_B2=as.numeric((lr1$coef)[3])
exp_B3=as.numeric((lr1$coef)[4])
exp_B4=as.numeric((lr1$coef)[5])
RaceWhite<-1
H=exp(B0+B1*age_mean+B2*income_mean+B3*ideology_mean+B4*RaceWhite)
B0=as.numeric((lr1$coef)[1])
B1=as.numeric((lr1$coef)[2])
B2=as.numeric((lr1$coef)[3])
B3=as.numeric((lr1$coef)[4])
B4=as.numeric((lr1$coef)[5])
H=exp(B0+B1*age_mean+B2*income_mean+B3*ideology_mean+B4*RaceWhite)
prob_vote_rep<-(H)/(1+H)
prob_vote_rep
RaceBlack=0
RaceWhite=1
H_white=exp(B0+B1*age_mean+B2*income_mean+B3*ideology_mean+B4*RaceWhite)
H_black=exp(B0+B1*age_mean+B2*income_mean+B3*ideology_mean+B4*RaceBlack)
prob_vote_rep_white<-(H_white)/(1+H_white)
prob_vote_rep_black<-(H_black)/(1+H_black)
diff<-prob_vote_rep_white<-(H_white)/(1+H_white)-prob_vote_rep_black<-(H_black)/(1+H_black)
diff<-prob_vote_rep_white-prob_vote_rep_black
diff
prob_vote_rep_black<-(H_black)/(1+H_black)
prob_vote_rep_black
RaceBlack=0
RaceWhite=1
odd_ratio_white=exp(B0+B1*age_mean+B2*income_mean+B3*ideology_mean+B4*RaceWhite)
odd_ratio_black=exp(B0+B1*age_mean+B2*income_mean+B3*ideology_mean+B4*RaceBlack)
prob_vote_rep_white<-(odd_ratio_white)/(1+odd_ratio_white)
prob_vote_rep_black<-(odd_ratio_black)/(1+odd_ratio_black)
diff<-prob_vote_rep_white-prob_vote_rep_black
diff
diff<-odd_ratio_white-odd_ratio_black
diff
age_increase_factor<-exp(50*B1)
age_increase_factor
income_increase_factor<-exp(1*B2)
income_increase_factor
lr2 <- glm(vote_rep ~ age + income + ideology_con+race_white+gender+partyid_rep,data=anes_2008tr,family="binomial")
lr2 <- glm(vote_rep ~ age + income + ideology_con+race_white+gender_male+partyid_rep,data=anes_2008tr,family="binomial")
anes_2008tr$
lr2 <- glm(vote_rep ~ age + income + ideology_con+ race_white+ gender_male+partyid_rep,data=anes_
2008tr,family="binomial")
summary(lr2)
lr2 <- glm(vote_rep ~ age + income + ideology_con+ race_white+ gender_male+partyid_rep,data=anes_
lr2 <- glm(vote_rep ~ age + income + ideology_con+ race_white+ gender_male+partyid_rep,             data=anes_2008tr,family="binomial")
reg <- glm(vote_rep ~ age + income + ideology_con+ race_white+ gender_male+partyid_rep,             data=anes_2008tr,family="binomial")
reg <- glm(vote_rep ~ age + income + ideology_con+ race_white+ gender_male+partyid_rep,             data=anes_2008tr,family="binomial")
summary(reg)
summary(lr1)
library(WDI)
gdp <- WDI(country=c("US","CA"),indicator="NY.GDP.PCAP.CD",start=1960,end=2011)
colnames(gdp)[3] <- "PerCapGDP"
library(ggplot2)
ggplot(gdp,aes(year,PerCapGDP,color=country)) + geom_line()
ggplot(gdp,aes(year,PerCapGDP,color=country)) + geom_line()
gdpUS
gdp
gdpUS <- gdp$PerCapGDP[gdp$country=="United States"]
gdpCA <- gdp$PerCapGDP[gdp$country=="Canada"]
summary(lm(gdpUS~gdpCA))
us <- rev(gdpUS)
us <- ts(us,start=1960,end=2011)
us.d1 <- diff(us)
plot(us.d1)
us.d1 <- diff(us)
lag0 <- us[2:(length(us) - 0)] # the original series
lag1 <- us[1:(length(us) - 1)] # the series "lagged" or offset by one year
us.d1a <- lag0 - lag1
cor(us.d1,us.d1a)
plot(us.d1)
plot(us.d1)
install.packages("forecast")
library(forecast)
ndiffs(us)
us.d2 <- diff(us,2)
plot(us.d2)
ca <- rev(gdpCA)
ca <- ts(ca,start=1960,end=2011)
ndiffs(ca)
ca.d2 <- diff(ca,2)
summary(lm(us.d2 ~ ca.d2))
us.d2.l0 <- us.d2[1:(length(us.d2)-1)] # original, but with one observation removed
ca.d2.l0 <- ca.d2[1:(length(ca.d2)-1)] # original, but with one observation removed
us.d2.l1 <- us.d2[2:(length(us.d2)-0)] # lag 1
ca.d2.l1 <- ca.d2[2:(length(ca.d2)-0)] # lag 1
summary(lm(us.d2.l0 ~ca.d2.l1 ))
summary(lm(ca.d2.l0 ~us.d2.l1 ))
pacf(us.d2)
acf(us.d2)
auto.arima(us)
arus <- auto.arima(us)
predict(arus,n.ahead=5)
usforecast <- forecast(object = arus, h=10)
plot(usforecast)
library(WDI)
gdp <- WDI(country=c("US","CA"),indicator="NY.GDP.PCAP.CD",start=1960,end=2011)
colnames(gdp)[3] <- "PerCapGDP"
library(ggplot2)
ggplot(gdp,aes(year,PerCapGDP,color=country)) + geom_line()
gdpUS <- gdp$PerCapGDP[gdp$country=="United States"]
gdpCA <- gdp$PerCapGDP[gdp$country=="Canada"]
summary(lm(gdpUS~gdpCA))
us <- rev(gdpUS)
us <- ts(us,start=1960,end=2011)
us.d1 <- diff(us)
lag0 <- us[2:(length(us) - 0)] # the original series
lag1 <- us[1:(length(us) - 1)] # the series "lagged" or offset by one year
us.d1a <- lag0 - lag1
cor(us.d1,us.d1a)
plot(us.d1) #Still has upward trend
install.packages("forecast")
library(forecast)
ndiffs(us)
us.d2 <- diff(us,2)
plot(us.d2)
# Doing the same work for Canada data
ca <- rev(gdpCA)
ca <- ts(ca,start=1960,end=2011)
ndiffs(ca)
ca.d2 <- diff(ca,2)
summary(lm(us.d2 ~ ca.d2))
#So they do appear to be correlated, even after differencing twice. But which one is causing the other? One simple way to examine this is to look at which is leading and which is lagging – that is, let’s regress one on the lag of the other, and then reverse the comparison; whichever model fits better suggests which variable is the lead (cause) and which variable is the effect. Is today’s US GDP better seen as a function of yesterday’s CA GDP, or is today’s CA GDP better seen as a function of yesterday’s US GDP?
#First we construct the sequences and lagged sequences:
us.d2.l0 <- us.d2[1:(length(us.d2)-1)] # original, but with one observation removed
ca.d2.l0 <- ca.d2[1:(length(ca.d2)-1)] # original, but with one observation removed
us.d2.l1 <- us.d2[2:(length(us.d2)-0)] # lag 1
ca.d2.l1 <- ca.d2[2:(length(ca.d2)-0)] # lag 1
summary(lm(us.d2.l0 ~ca.d2.l1 ))
summary(lm(ca.d2.l0 ~us.d2.l1 ))
pacf(us.d2)  #Yt=β1Y(t−1)+β2Y(t−2)+...
#We can replicate this more or less using regression, shown here for the first four lags:
us.d2.l0 <- us.d2[5:(length(us.d2) - 0)]
us.d2.l1 <- us.d2[4:(length(us.d2) - 1)]
us.d2.l2 <- us.d2[3:(length(us.d2) - 2)]
us.d2.l3 <- us.d2[2:(length(us.d2) - 3)]
us.d2.l4 <- us.d2[1:(length(us.d2) - 4)]
summary(lm(us.d2.l0 ~ us.d2.l1 + us.d2.l2 + us.d2.l3 + us.d2.l4))
#Y might  be a moving average (MA) of its past values
#Rather than having a very short memory, where the value Yt is only a function of Yt−1 and a few more lags, instead Yt is a function of lots of past lags, all contributing very small amounts.
acf(us.d2)
#Of course, as with all models, in the real world we can’t really assess one or the other model – AR or MA – independently. Instead, our process could be a mix of both – a little bit of auto-regression, where the immediate past values of Y influence the next values; and a little bit of moving average, where the long-term history of Y tends to have a gradual effect on the future. So to estimate the best model, we need to try a variety of mixtures of AR and MA, and see which model best fits the data (using, for instance, the Akaike Information Criterion, which is like R2 but generalizes to all kinds of models, not just linear regression).
#As usual, R will do our hard work for us. In the forecast package is the auto.arima function, which will find the best mix of AR and MA. ARIMA, of course stands for AR+MA, plus the I, which stands for “integrated” but usually is equivalent to how many differencings you have to do to the data first before doing the AR and MA analysis. Thus an ARIMA (1,2,0) model would be a model with 2 differencings, an AR(1) process (ie, Yt is partially correlated with Yt−1 but none of the other lags), and a MA(0) (ie, no moving average) part. A (2,1,1) ARIMA process would have an AR(2) component, 1 first-differencing, and a MA(1) component.
auto.arima(us)
################
auto.arima(us,xreg=ca)
auto.arima(ca,xreg=us)
##############
#Prediction
arus <- auto.arima(us)
predict(arus,n.ahead=5)
usforecast <- forecast(object = arus, h=10)
plot(usforecast)
install.packages("forecast")
